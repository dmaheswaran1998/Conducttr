{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, json, requests\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import data_config\n",
    "import re\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "consumer_key = data_config.consumer_key\n",
    "partition_id = data_config.partition_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_following(consumer_key,partition_id):\n",
    "    url = data_config.get_following+partition_id\n",
    "    headers = {\"Authorization\":\"Bearer \"+consumer_key}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = json.loads(response.content)\n",
    "    \n",
    "    return data[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_permissions(consumer_key,partition_id):\n",
    "    url = data_config.get_permssions+partition_id\n",
    "    headers = {\"Authorization\":\"Bearer \"+consumer_key}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    #print(response)\n",
    "    data = json.loads(response.content)\n",
    "    data = data[\"response\"][\"permissions\"]\n",
    "    return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timeline and type of interaction \n",
    "def get_message_data(consumer_key,partition_id):\n",
    "    url = data_config.get_activity+partition_id\n",
    "    headers = {\"Authorization\":\"Bearer \"+consumer_key}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = json.loads(response.content)\n",
    "    #st.write(data)\n",
    "    timeline = data[\"detailed_log\"]\n",
    "    summary = data[\"summary\"]\n",
    "    return timeline, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what is positions who can edit, probably not needed \n",
    "def get_cloud_personas(consumer_key,partition_id):\n",
    "    url = data_config.get_personas+partition_id\n",
    "    headers = {\"Authorization\":\"Bearer \"+consumer_key}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = json.loads(response.content)\n",
    "    return data[\"response\"][\"personas\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates from the list\n",
    "def remove_duplicates(list, unique_list):\n",
    "    for item in list:\n",
    "        if item not in unique_list:\n",
    "            unique_list.append(item)\n",
    "    return unique_list            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_bracket(list):\n",
    "    list1=[]\n",
    "    for item in list:\n",
    "        item2 = item[1:]\n",
    "        list1.append(item2)\n",
    "    return list1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=get_message_data(consumer_key,partition_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=list(data)\n",
    "keys=data[0].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates=[]\n",
    "for i in keys:\n",
    "    dates.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persona_id=[]\n",
    "for i in range(0, len(dates)):\n",
    "    id=dates[i][-5:]\n",
    "    persona_id.append(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values1=[]\n",
    "values=data[0].values()\n",
    "for i in values:\n",
    "    values1.append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the reponse based on the channel \n",
    "channel=[]\n",
    "interaction=[]\n",
    "RFI=[]\n",
    "text=[]\n",
    "id1=[]\n",
    "id2=[]\n",
    "\n",
    "for i in range(0, len(values1)):\n",
    "    x = values1[i].split(\"]\")\n",
    "    channel.append(x[0])\n",
    "    interaction.append(x[1])\n",
    "    RFI.append(x[2])\n",
    "    text.append(x[3])\n",
    "    id1.append(x[4])\n",
    "    id2.append(x[5])\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction=remove_bracket(interaction)\n",
    "channel=remove_bracket(channel)\n",
    "RFI=remove_bracket(RFI)\n",
    "text=remove_bracket(text)\n",
    "id1=remove_bracket(id1)\n",
    "id2=remove_bracket(id2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#editing the text cell in more detail \n",
    "#need to remove the <br / br> \n",
    "#also need to remove the //\n",
    "text2=[]\n",
    "for item in text:\n",
    "    edited_text=re.sub(\"(<br\\s*/>)\",\"\", item)\n",
    "    edited_text=re.sub(\"(<b)\",\"\", edited_text)\n",
    "    edited_text=edited_text.replace(\"\\\\\",\"\")\n",
    "    text2.append(edited_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#editing the date:\n",
    "dates\n",
    "dates2=[]\n",
    "for item in dates:\n",
    "    item1=item[:-6]\n",
    "    dates2.append(item1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({\"date\": dates2, \"persona_id\":persona_id,\"channel\": channel, \"interaction\": interaction, \n",
    "                 \"Text\":text2, \"From\": id1, \"To\":id2})\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persona=get_cloud_personas(consumer_key,partition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persona_id\n",
    "unique_persona_id=[]\n",
    "for item in persona_id:\n",
    "    if item not in unique_persona_id:\n",
    "        unique_persona_id.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linking the ids with the unique persona, need to understand the json document that need sto do thisu\n",
    "\n",
    "persona_keys=persona.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "imageURL=[]\n",
    "type=[]\n",
    "\n",
    "for item in unique_persona_id:\n",
    "    name.append(persona[item][\"details\"][\"name\"])\n",
    "    imageURL.append(persona[item][\"details\"][\"imageUrl\"])\n",
    "    type.append(persona[item][\"details\"][\"type\"])\n",
    "    \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persona_df=pd.DataFrame({\"persona_id\":unique_persona_id, \"name\": name, \"image_url\":imageURL, \"type\":type})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persona_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing blank spaces\n",
    "nospace_id2=list(filter(None, id2))\n",
    "\n",
    "edited_list2 = [y for x in nospace_id2 for y in x.split(',')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting a list of unique_ids\n",
    "all_ids=id1+edited_list2\n",
    "unique_ids=[]\n",
    "remove_duplicates(all_ids, unique_ids)\n",
    "unique_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter=[]\n",
    "twitter_number=[]\n",
    "twitter_followers=[]\n",
    "twitter_following=[]\n",
    "email=[]\n",
    "\n",
    "gosocial_name=[]\n",
    "gosocial_number=[]\n",
    "gosocial_followers=[]\n",
    "\n",
    "\n",
    "for item in unique_ids:\n",
    "    #twitter data\n",
    "    twitter.append(persona[item][\"microblog\"][\"displayName\"])\n",
    "    twitter_number.append(persona[item][\"microblog\"][\"numMessages\"])\n",
    "    twitter_followers.append(persona[item][\"microblog\"][\"followers\"])\n",
    "    twitter_following.append(persona[item][\"microblog\"][\"following\"])\n",
    "    \n",
    "    #email\n",
    "    email.append(persona[item][\"mail\"][\"email\"])\n",
    "    \n",
    "    #GoSocial\n",
    "    gosocial_name.append(persona[item][\"gosocial\"][\"displayName\"])\n",
    "    gosocial_number.append(persona[item][\"gosocial\"][\"numMessages\"])\n",
    "    gosocial_followers.append(persona[item][\"gosocial\"][\"followers\"])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Player_activity_dataset\n",
    "\n",
    "channel_df=pd.DataFrame({\"From\":unique_ids, \"twitter name\":twitter, \"twitter messages\":twitter_number,\n",
    "             \"twitter followers\":twitter_followers, \"twitter_following\":twitter_following,\n",
    "             \"email\":email, \"goSocial name\": gosocial_name, \"goSocial messages\": gosocial_number, \"goSocial Followers\":gosocial_followers\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "channel_df.head(20)\n",
    "\n",
    "\n",
    "##to_merged=channel_df[[\"To\", ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel2_df=pd.DataFrame({\"To\":unique_ids, \"From\":unique_ids, \"twitter name\":twitter, \"twitter messages\":twitter_number,\n",
    "             \"twitter followers\":twitter_followers, \"twitter_following\":twitter_following,\n",
    "             \"email\":email, \"goSocial name\": gosocial_name, \"goSocial messages\": gosocial_number, \"goSocial Followers\":gosocial_followers\n",
    "    \n",
    "})\n",
    "\n",
    "channel2_df['twitter name'] = channel2_df['twitter name'].str.replace('[^\\w\\s#@/:%.,_-]', '', flags=re.UNICODE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_merged=channel2_df[[\"From\", \"twitter name\", \"email\", \"goSocial name\"]]\n",
    "from_merged.head(20)\n",
    "#string replacements in the from dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_merged=channel2_df[[\"To\", \"twitter name\"]]\n",
    "All=[\"All\"]\n",
    "All=pd.DataFrame({\"To\":All, \"twitter name\":All})\n",
    "to_merged=to_merged.append(All)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_merged.head(50)\n",
    "#remove emojis from the dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explode the id2 dataframe count:\n",
    "to_merged[\"twitter name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chainer(s):\n",
    "    return list(chain.from_iterable(s.str.split(',')))\n",
    "\n",
    "# calculate lengths of splits\n",
    "lens = df['To'].str.split(',').map(len)\n",
    "\n",
    "# create new dataframe, repeating or chaining as appropriate\n",
    "df2 = pd.DataFrame({'date': np.repeat(df['date'], lens),\n",
    "                    'persona_id': np.repeat(df['persona_id'], lens),\n",
    "                    'channel': np.repeat(df['channel'], lens),\n",
    "                    'interaction': np.repeat(df['interaction'], lens),\n",
    "                    'Text': np.repeat(df['Text'], lens),\n",
    "                    'From': np.repeat(df['From'], lens),\n",
    "                    'To': chainer(df['To'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data - getting across it and unferstanding it\n",
    "df2[\"Frequency\"]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged=pd.merge(df2, from_merged, on='From')\n",
    "merged.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged=merged.rename(columns={\"twitter name\":\"from\"})\n",
    "merged=merged.drop(columns={\"From\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill null values in NA\n",
    "merged['To'].replace('','Everyone', inplace=True)\n",
    "merged['email'].replace('','None', inplace=True)\n",
    "merged['goSocial name'].replace('','None', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_2=pd.merge(merged,to_merged, on='To')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_2=merged_2.rename(columns={\"twitter name\":\"to\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge persona id: \n",
    "\n",
    "#merging people\n",
    "merged_final=pd.merge(merged_2,persona_df, on='persona_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_final=merged_final[[\"date\",\"name\",\"channel\", \"interaction\", \"Text\", \"from\", \"to\", \"image_url\", \"type\", \"Frequency\",\"email\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total interactions of each (name) and channel \n",
    "total_interactions = merged_final.groupby(['name','channel','interaction'])\n",
    "total_interactions_final=pd.DataFrame(total_interactions[\"Frequency\"].count())\n",
    "total_interactions_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#personas each person had as each person (from interactions) \n",
    "total_to = merged_final.groupby(['name','to'])\n",
    "total_to=pd.DataFrame(total_to[\"Frequency\"].count())\n",
    "total_to.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_from = merged_final.groupby(['name','from'])\n",
    "total_from=pd.DataFrame(total_from[\"Frequency\"].count())\n",
    "total_from.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_from_channel= merged_final.groupby(['name','from','channel'])\n",
    "total_from_channel=pd.DataFrame(total_from_channel[\"Frequency\"].count())\n",
    "total_from_channel.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#personas most communications- channel and person \n",
    "total_group = merged_final.groupby(['name','to', \"channel\"])\n",
    "total_to=pd.DataFrame(total_group[\"Frequency\"].count())\n",
    "total_to.head(50)\n",
    "\n",
    "merged_final_df=merged_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#personas by the different day, interaction (to whom- as tooltip) maybe\n",
    "\n",
    "#received communication\n",
    "#receiving time and trying to get those filters to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write out to a json file\n",
    "results = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "for index, value in total_from.itertuples():\n",
    "    for i, key in enumerate(index):\n",
    "        if i == 0:\n",
    "            nested = results[key]\n",
    "        elif i == len(index) - 1:\n",
    "            nested[key] = value\n",
    "        else:\n",
    "            nested = nested[key] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list=[]\n",
    "newlist = list()\n",
    "for i in results.keys():\n",
    "    newlist.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impersonations2={}\n",
    "for item in newlist:\n",
    "        impersonations=results[item].keys()\n",
    "        values=[]\n",
    "        for i in impersonations:    \n",
    "            values.append(i)\n",
    "            impersonations2.update({f'{item}':values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impersonations3={\"impersonations\": impersonations2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list.append(impersonations3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_final2=merged_final.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_final2[\"channel\"]=\"All\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=(merged_final, merged_final2)\n",
    "merged3=pd.concat(frames)\n",
    "merged3.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_from_channel= merged3.groupby(['name','from','channel'])\n",
    "total_from_channel=pd.DataFrame(total_from_channel[\"Frequency\"].count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results3 = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "for index, value in total_from_channel.itertuples():\n",
    "    for i, key in enumerate(index):\n",
    "        if i == 0:\n",
    "            nested = results3[key]\n",
    "        elif i == len(index) - 1:\n",
    "            nested[key] = value\n",
    "        else:\n",
    "            nested = nested[key] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results4={\"from\":results3}\n",
    "json_list.append(results4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping the datetime \n",
    "merged3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged3['date'] = pd.to_datetime(merged3['date'], infer_datetime_format=True)\n",
    "merged3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged3_copy=merged3.copy()\n",
    "merged3_copy['channel']=\"All\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=[merged3, merged3_copy]\n",
    "merged4=pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of unique values and getting a JSON file for frequency of all the players \n",
    "person_list=merged4['name'].to_list()\n",
    "\n",
    "person_list_unique=[]\n",
    "\n",
    "for item in person_list:\n",
    "    if item not in person_list_unique:\n",
    "        person_list_unique.append(item)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_list=merged4[\"channel\"].to_list()\n",
    "channel_list_unique=[]\n",
    "for item in channel_list:\n",
    "    if item not in channel_list_unique:\n",
    "        channel_list_unique.append(item)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_list_unique\n",
    "dict2={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_list_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jsonifying the data \n",
    "for person in person_list_unique:\n",
    "    frames=[]\n",
    "    for channel in channel_list_unique:\n",
    "        try:\n",
    "            channel_1=merged4.loc[(merged4[\"name\"]==f\"{person}\") &(merged4[\"channel\"]==f'{channel}'), :]\n",
    "            merged_time_all=channel_1.resample('0.3H', on='date').sum()\n",
    "            merged_time_all[\"channel\"]=f\"{channel}\"\n",
    "            frames.append(merged_time_all)\n",
    "        except:\n",
    "            continue\n",
    "   \n",
    "    merged=pd.concat(frames)\n",
    "    merged=merged.reset_index()\n",
    "    merged['date']=merged['date'].astype(str)\n",
    "    merged = merged.groupby(['channel', \"date\"])\n",
    "    merged1=pd.DataFrame(merged[\"Frequency\"].sum())\n",
    "    \n",
    "    results1 = defaultdict(lambda: defaultdict(dict))\n",
    "    for index, value in merged1.itertuples():\n",
    "        for i, key in enumerate(index):\n",
    "            if i == 0:\n",
    "                nested = results1[key]\n",
    "            elif i == len(index) - 1:\n",
    "                nested[key] = value\n",
    "        else:\n",
    "            nested = nested[key]\n",
    "    \n",
    "    \n",
    "    dict2.update({f'{person}':results1})\n",
    "        \n",
    "    \n",
    "            \n",
    "            \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_to_channel= merged3.groupby(['name','to','channel'])\n",
    "total_to_channel=pd.DataFrame(total_to_channel[\"Frequency\"].count())\n",
    "total_to_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results5 = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "for index, value in total_to_channel.itertuples():\n",
    "    for i, key in enumerate(index):\n",
    "        if i == 0:\n",
    "            nested = results5[key]\n",
    "        elif i == len(index) - 1:\n",
    "            nested[key] = value\n",
    "        else:\n",
    "            nested = nested[key] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results6={\"to\":results5}\n",
    "results6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list.append(results6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list.append(dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('player_data.json', 'w') as fp:\n",
    "    json.dump(json_list, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
